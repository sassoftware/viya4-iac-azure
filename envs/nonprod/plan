
Terraform used the selected providers to generate the following execution
plan. Resource actions are indicated with the following symbols:
  + create
 <= read (data resources)

Terraform will perform the following actions:

  # data.template_cloudinit_config.jump[0] will be read during apply
  # (config refers to values not yet known)
 <= data "template_cloudinit_config" "jump"  {
      + base64_encode = true
      + gzip          = true
      + id            = (known after apply)
      + rendered      = (known after apply)

      + part {
          + content      = (known after apply)
          + content_type = "text/cloud-config"
        }
    }

  # data.template_file.jump-cloudconfig[0] will be read during apply
  # (config refers to values not yet known)
 <= data "template_file" "jump-cloudconfig"  {
      + id       = (known after apply)
      + rendered = (known after apply)
      + template = <<-EOT
            #cloud-config
            system_info:
              default_user:
                name: ${vm_admin}
            
            #
            # Update the repo and then update the OS
            #
            package_update: true
            package_upgrade: true
            
            #
            # Install Docker Pre-Reqs
            # Verify Docker Hash / Key: $curl -sL https://download.docker.com/linux/ubuntu/gpg | gpg
            #
            apt:
              sources:
                docker.list:
                  source: deb [arch=amd64] https://download.docker.com/linux/ubuntu $RELEASE stable
                  keyid: 9DC858229FC7DD38854AE2D88D81803C0EBFCD88
            
            #
            # Install packages: nfs, docker
            #
            packages:
              - nfs-common
              - docker-ce
              - docker-ce-cli
            
            #
            # Update /etc/fstab
            #
            mounts:
              - ${mounts}
            
            #
            # Add nfs mounts
            #
            runcmd:
              - if ! [ -z "${rwx_filestore_endpoint}" ]
              - then
                  #
                  # mount the nfs
                  #
              -   while [ `df -h | grep "${rwx_filestore_endpoint}:${rwx_filestore_path}" | wc -l` -eq 0 ]; do sleep 5 && mount -a ; done
                  #
                  # Change permissions and owner
                  #
              -   mkdir -p ${jump_rwx_filestore_path}/pvs
              -   $(chmod -fR 777 ${jump_rwx_filestore_path} ; echo)
              -   $(chown -R nobody:nogroup ${jump_rwx_filestore_path} ; echo)
              - fi
              #
              # Update user for Docker, user=${vm_admin}
              #
              - usermod -aG docker ${vm_admin}
        EOT
      + vars     = {
          + "jump_rwx_filestore_path" = "/viya-share"
          + "mounts"                  = (known after apply)
          + "rwx_filestore_endpoint"  = (known after apply)
          + "rwx_filestore_path"      = "/export"
          + "vm_admin"                = "edcadmin"
        }
    }

  # azurerm_proximity_placement_group.proximity[0] will be created
  + resource "azurerm_proximity_placement_group" "proximity" {
      + id                  = (known after apply)
      + location            = "uaenorth"
      + name                = "zandsas-ProximityPlacementGroup"
      + resource_group_name = "shd-sas-k8s-rg-n"
    }

  # azurerm_user_assigned_identity.uai[0] will be created
  + resource "azurerm_user_assigned_identity" "uai" {
      + client_id           = (known after apply)
      + id                  = (known after apply)
      + location            = "uaenorth"
      + name                = "zandsas-aks-identity"
      + principal_id        = (known after apply)
      + resource_group_name = "shd-sas-k8s-rg-n"
      + tenant_id           = (known after apply)
    }

  # kubernetes_config_map.sas_iac_buildinfo will be created
  + resource "kubernetes_config_map" "sas_iac_buildinfo" {
      + data = {
          + "git-hash"    = "bdc8c8471365ef223bbf164c462d6f2a1e3d0b9a"
          + "iac-tooling" = "terraform"
          + "terraform"   = <<-EOT
                version: "1.0.6"
                revision: null
                provider-selections: {"registry.terraform.io/hashicorp/azuread":"1.5.0","registry.terraform.io/hashicorp/azurerm":"2.62.0","registry.terraform.io/hashicorp/cloudinit":"2.2.0","registry.terraform.io/hashicorp/external":"2.1.0","registry.terraform.io/hashicorp/kubernetes":"2.3.1","registry.terraform.io/hashicorp/local":"2.1.0","registry.terraform.io/hashicorp/null":"3.1.0","registry.terraform.io/hashicorp/template":"2.2.0","registry.terraform.io/hashicorp/tls":"3.1.0"}
                outdated: true
            EOT
        }
      + id   = (known after apply)

      + metadata {
          + generation       = (known after apply)
          + name             = "sas-iac-buildinfo"
          + namespace        = "kube-system"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }
    }

  # module.aks.data.azurerm_public_ip.cluster_public_ip[0] will be read during apply
  # (config refers to values not yet known)
 <= data "azurerm_public_ip" "cluster_public_ip"  {
      + allocation_method       = (known after apply)
      + domain_name_label       = (known after apply)
      + fqdn                    = (known after apply)
      + id                      = (known after apply)
      + idle_timeout_in_minutes = (known after apply)
      + ip_address              = (known after apply)
      + ip_tags                 = (known after apply)
      + ip_version              = (known after apply)
      + location                = (known after apply)
      + name                    = (known after apply)
      + resource_group_name     = "MC_shd-sas-k8s-rg-n_zandsas-aks_uaenorth"
      + reverse_fqdn            = (known after apply)
      + sku                     = (known after apply)
      + zones                   = (known after apply)

      + timeouts {
          + read = (known after apply)
        }
    }

  # module.aks.azurerm_kubernetes_cluster.aks will be created
  + resource "azurerm_kubernetes_cluster" "aks" {
      + dns_prefix              = "zandsas-aks"
      + fqdn                    = (known after apply)
      + id                      = (known after apply)
      + kube_admin_config       = (known after apply)
      + kube_admin_config_raw   = (sensitive value)
      + kube_config             = (known after apply)
      + kube_config_raw         = (sensitive value)
      + kubelet_identity        = (known after apply)
      + kubernetes_version      = "1.21.7"
      + location                = "uaenorth"
      + name                    = "zandsas-aks"
      + node_resource_group     = (known after apply)
      + private_cluster_enabled = false
      + private_dns_zone_id     = (known after apply)
      + private_fqdn            = (known after apply)
      + private_link_enabled    = (known after apply)
      + resource_group_name     = "shd-sas-k8s-rg-n"
      + sku_tier                = "Free"

      + addon_profile {

          + http_application_routing {
              + enabled                            = false
              + http_application_routing_zone_name = (known after apply)
            }

          + kube_dashboard {
              + enabled = false
            }

          + oms_agent {
              + enabled            = false
              + oms_agent_identity = (known after apply)
            }
        }

      + auto_scaler_profile {
          + balance_similar_node_groups      = (known after apply)
          + empty_bulk_delete_max            = (known after apply)
          + expander                         = (known after apply)
          + max_graceful_termination_sec     = (known after apply)
          + max_node_provisioning_time       = (known after apply)
          + max_unready_nodes                = (known after apply)
          + max_unready_percentage           = (known after apply)
          + new_pod_scale_up_delay           = (known after apply)
          + scale_down_delay_after_add       = (known after apply)
          + scale_down_delay_after_delete    = (known after apply)
          + scale_down_delay_after_failure   = (known after apply)
          + scale_down_unneeded              = (known after apply)
          + scale_down_unready               = (known after apply)
          + scale_down_utilization_threshold = (known after apply)
          + scan_interval                    = (known after apply)
          + skip_nodes_with_local_storage    = (known after apply)
          + skip_nodes_with_system_pods      = (known after apply)
        }

      + default_node_pool {
          + availability_zones    = []
          + enable_auto_scaling   = true
          + enable_node_public_ip = false
          + max_count             = 5
          + max_pods              = 110
          + min_count             = 2
          + name                  = "system"
          + node_count            = 2
          + node_taints           = []
          + orchestrator_version  = "1.21.7"
          + os_disk_size_gb       = 128
          + os_disk_type          = "Managed"
          + type                  = "VirtualMachineScaleSets"
          + vm_size               = "Standard_D8s_v4"
          + vnet_subnet_id        = "/subscriptions/76f40aaa-eacd-4fd8-a046-3bd07855f6f8/resourceGroups/shd-network-rg-n/providers/Microsoft.Network/virtualNetworks/SHD-INF-VNET-n/subnets/shd-inf-sas-k8s-10.23.8.64-26-n"
        }

      + identity {
          + principal_id              = (known after apply)
          + tenant_id                 = (known after apply)
          + type                      = (known after apply)
          + user_assigned_identity_id = (known after apply)
        }

      + linux_profile {
          + admin_username = "azureuser"

          + ssh_key {
              + key_data = <<-EOT
                    ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCb41cp8jHN4XwSf/9XLFEXunJKuh7XycKRADBvTr2VLgQ8ZngnvoOff3huHpoZBGnq7PQ6kVSx1H6rLTTQX7nrLMERLl/3Kv4b841tNOvrhxWyj1g7jo9e93aRX8YgoGdjts+jm61k06LPI4u/LRJt9j1177kQEXZPFfWCF9n26hN5LlmNUZ1xw5N8agx5EEJOicHOJWUAT3mZdQ1czuiivMU7PKdz5iW2KoJmjoR3EHaPJ4zM1pcZfHdPhj+u5J+l1WMCEU37jumNAdu9QSysXppC3ZOHHuOlGGgeC+FFChfuK4Bc4ha/FjwB8w0DQj4doTMuFZ3PVwDT2hEPQA4fQAE8lG0wNUFLUWHiTiCZr0Lg6eFcqgF1M+nNv5w2JE8TKMkXqi8c5VDoFuwOcvj54H1yDRjAh1aPUF8Ofg0iGlx0hKFzT9QJyiT9cJWfvOlG9C/+f/fNnuzOAn/pYncfB+RvkudFhSDzIBIb5ay3PeHPa8iC4xImg947sbK2N7U= Shariq.Mustquim@MBP-C02C32F6MD6R
                EOT
            }
        }

      + network_profile {
          + dns_service_ip     = "10.0.0.10"
          + docker_bridge_cidr = "172.17.0.1/16"
          + load_balancer_sku  = "Standard"
          + network_mode       = (known after apply)
          + network_plugin     = "kubenet"
          + network_policy     = (known after apply)
          + outbound_type      = "loadBalancer"
          + pod_cidr           = "10.244.0.0/16"
          + service_cidr       = "10.0.0.0/16"

          + load_balancer_profile {
              + effective_outbound_ips    = (known after apply)
              + idle_timeout_in_minutes   = (known after apply)
              + managed_outbound_ip_count = (known after apply)
              + outbound_ip_address_ids   = (known after apply)
              + outbound_ip_prefix_ids    = (known after apply)
              + outbound_ports_allocated  = (known after apply)
            }
        }

      + role_based_access_control {
          + enabled = true
        }

      + service_principal {
          + client_id     = (known after apply)
          + client_secret = (sensitive value)
        }

      + timeouts {
          + create = "90m"
          + delete = "90m"
          + read   = "5m"
          + update = "90m"
        }

      + windows_profile {
          + admin_password = (sensitive value)
          + admin_username = (known after apply)
        }
    }

  # module.jump[0].azurerm_linux_virtual_machine.vm will be created
  + resource "azurerm_linux_virtual_machine" "vm" {
      + admin_username                  = "edcadmin"
      + allow_extension_operations      = true
      + computer_name                   = (known after apply)
      + custom_data                     = (sensitive value)
      + disable_password_authentication = true
      + extensions_time_budget          = "PT1H30M"
      + id                              = (known after apply)
      + location                        = "uaenorth"
      + max_bid_price                   = -1
      + name                            = "zandsas-jump-vm"
      + network_interface_ids           = (known after apply)
      + platform_fault_domain           = -1
      + priority                        = "Regular"
      + private_ip_address              = (known after apply)
      + private_ip_addresses            = (known after apply)
      + provision_vm_agent              = true
      + public_ip_address               = (known after apply)
      + public_ip_addresses             = (known after apply)
      + resource_group_name             = "shd-sas-k8s-rg-n"
      + size                            = "Standard_B2s"
      + virtual_machine_id              = (known after apply)
      + zone                            = (known after apply)

      + additional_capabilities {
          + ultra_ssd_enabled = false
        }

      + admin_ssh_key {
          + public_key = <<-EOT
                ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCb41cp8jHN4XwSf/9XLFEXunJKuh7XycKRADBvTr2VLgQ8ZngnvoOff3huHpoZBGnq7PQ6kVSx1H6rLTTQX7nrLMERLl/3Kv4b841tNOvrhxWyj1g7jo9e93aRX8YgoGdjts+jm61k06LPI4u/LRJt9j1177kQEXZPFfWCF9n26hN5LlmNUZ1xw5N8agx5EEJOicHOJWUAT3mZdQ1czuiivMU7PKdz5iW2KoJmjoR3EHaPJ4zM1pcZfHdPhj+u5J+l1WMCEU37jumNAdu9QSysXppC3ZOHHuOlGGgeC+FFChfuK4Bc4ha/FjwB8w0DQj4doTMuFZ3PVwDT2hEPQA4fQAE8lG0wNUFLUWHiTiCZr0Lg6eFcqgF1M+nNv5w2JE8TKMkXqi8c5VDoFuwOcvj54H1yDRjAh1aPUF8Ofg0iGlx0hKFzT9QJyiT9cJWfvOlG9C/+f/fNnuzOAn/pYncfB+RvkudFhSDzIBIb5ay3PeHPa8iC4xImg947sbK2N7U= Shariq.Mustquim@MBP-C02C32F6MD6R
            EOT
          + username   = "edcadmin"
        }

      + os_disk {
          + caching                   = "ReadOnly"
          + disk_size_gb              = 64
          + name                      = (known after apply)
          + storage_account_type      = "Standard_LRS"
          + write_accelerator_enabled = false
        }

      + source_image_reference {
          + offer     = "0001-com-ubuntu-server-focal"
          + publisher = "Canonical"
          + sku       = "20_04-lts"
          + version   = "latest"
        }
    }

  # module.jump[0].azurerm_network_interface.vm_nic will be created
  + resource "azurerm_network_interface" "vm_nic" {
      + applied_dns_servers           = (known after apply)
      + dns_servers                   = (known after apply)
      + enable_accelerated_networking = false
      + enable_ip_forwarding          = false
      + id                            = (known after apply)
      + internal_dns_name_label       = (known after apply)
      + internal_domain_name_suffix   = (known after apply)
      + location                      = "uaenorth"
      + mac_address                   = (known after apply)
      + name                          = "zandsas-jump-nic"
      + private_ip_address            = (known after apply)
      + private_ip_addresses          = (known after apply)
      + resource_group_name           = "shd-sas-k8s-rg-n"
      + virtual_machine_id            = (known after apply)

      + ip_configuration {
          + name                          = "zandsas-jump-ip_config"
          + primary                       = (known after apply)
          + private_ip_address            = (known after apply)
          + private_ip_address_allocation = "dynamic"
          + private_ip_address_version    = "IPv4"
          + public_ip_address_id          = (known after apply)
          + subnet_id                     = "/subscriptions/76f40aaa-eacd-4fd8-a046-3bd07855f6f8/resourceGroups/shd-network-rg-n/providers/Microsoft.Network/virtualNetworks/SHD-INF-VNET-n/subnets/shd-inf-sas-k8s-10.23.8.64-26-n"
        }
    }

  # module.jump[0].azurerm_network_interface_security_group_association.vm_nic_sg will be created
  + resource "azurerm_network_interface_security_group_association" "vm_nic_sg" {
      + id                        = (known after apply)
      + network_interface_id      = (known after apply)
      + network_security_group_id = "/subscriptions/76f40aaa-eacd-4fd8-a046-3bd07855f6f8/resourceGroups/shd-network-rg-n/providers/Microsoft.Network/networkSecurityGroups/shd-inf-sas-k8s-10.23.8.64-26-n-nsg"
    }

  # module.jump[0].azurerm_public_ip.vm_ip[0] will be created
  + resource "azurerm_public_ip" "vm_ip" {
      + allocation_method       = "Static"
      + fqdn                    = (known after apply)
      + id                      = (known after apply)
      + idle_timeout_in_minutes = 4
      + ip_address              = (known after apply)
      + ip_version              = "IPv4"
      + location                = "uaenorth"
      + name                    = "zandsas-jump-public_ip"
      + resource_group_name     = "shd-sas-k8s-rg-n"
      + sku                     = "Basic"
      + zones                   = []
    }

  # module.kubeconfig.data.kubernetes_secret.sa_secret[0] will be read during apply
  # (config refers to values not yet known)
 <= data "kubernetes_secret" "sa_secret"  {
      + data = (sensitive value)
      + id   = (known after apply)
      + type = (known after apply)

      + metadata {
          + generation       = (known after apply)
          + name             = (known after apply)
          + namespace        = "kube-system"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }
    }

  # module.kubeconfig.data.template_file.kubeconfig_sa[0] will be read during apply
  # (config refers to values not yet known)
 <= data "template_file" "kubeconfig_sa"  {
      + id       = (known after apply)
      + rendered = (known after apply)
      + template = <<-EOT
            apiVersion: v1
            kind: Config
            clusters:
              - name: ${cluster_name}
                cluster:
                  server: '${endpoint}'
                  certificate-authority-data: >-
                    ${ca_crt}
            users:
              - name: ${name}
                user:
                  token: >-
                    ${token}
            contexts:
              - name: ${cluster_name}    
                context:
                  user: ${name}
                  cluster: ${cluster_name}
                  namespace: ${namespace}
            current-context: ${cluster_name}
        EOT
      + vars     = {
          + "ca_crt"       = (known after apply)
          + "cluster_name" = "zandsas-aks"
          + "endpoint"     = (known after apply)
          + "name"         = "zandsas-cluster-admin-sa"
          + "namespace"    = "kube-system"
          + "token"        = (known after apply)
        }
    }

  # module.kubeconfig.kubernetes_cluster_role_binding.kubernetes_crb[0] will be created
  + resource "kubernetes_cluster_role_binding" "kubernetes_crb" {
      + id = (known after apply)

      + metadata {
          + generation       = (known after apply)
          + name             = "zandsas-cluster-admin-crb"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }

      + role_ref {
          + api_group = "rbac.authorization.k8s.io"
          + kind      = "ClusterRole"
          + name      = "cluster-admin"
        }

      + subject {
          + api_group = (known after apply)
          + kind      = "ServiceAccount"
          + name      = "zandsas-cluster-admin-sa"
          + namespace = "kube-system"
        }
    }

  # module.kubeconfig.kubernetes_service_account.kubernetes_sa[0] will be created
  + resource "kubernetes_service_account" "kubernetes_sa" {
      + automount_service_account_token = true
      + default_secret_name             = (known after apply)
      + id                              = (known after apply)

      + metadata {
          + generation       = (known after apply)
          + name             = "zandsas-cluster-admin-sa"
          + namespace        = "kube-system"
          + resource_version = (known after apply)
          + uid              = (known after apply)
        }
    }

  # module.kubeconfig.local_file.kubeconfig will be created
  + resource "local_file" "kubeconfig" {
      + content              = (known after apply)
      + directory_permission = "0755"
      + file_permission      = "0644"
      + filename             = "zandsas-aks-kubeconfig.conf"
      + id                   = (known after apply)
    }

  # module.nfs[0].azurerm_linux_virtual_machine.vm will be created
  + resource "azurerm_linux_virtual_machine" "vm" {
      + admin_username                  = "edcadmin"
      + allow_extension_operations      = true
      + computer_name                   = (known after apply)
      + custom_data                     = (sensitive value)
      + disable_password_authentication = true
      + extensions_time_budget          = "PT1H30M"
      + id                              = (known after apply)
      + location                        = "uaenorth"
      + max_bid_price                   = -1
      + name                            = "zandsas-nfs-vm"
      + network_interface_ids           = (known after apply)
      + platform_fault_domain           = -1
      + priority                        = "Regular"
      + private_ip_address              = (known after apply)
      + private_ip_addresses            = (known after apply)
      + provision_vm_agent              = true
      + proximity_placement_group_id    = (known after apply)
      + public_ip_address               = (known after apply)
      + public_ip_addresses             = (known after apply)
      + resource_group_name             = "shd-sas-k8s-rg-n"
      + size                            = "Standard_D8s_v4"
      + virtual_machine_id              = (known after apply)
      + zone                            = (known after apply)

      + additional_capabilities {
          + ultra_ssd_enabled = false
        }

      + admin_ssh_key {
          + public_key = <<-EOT
                ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCb41cp8jHN4XwSf/9XLFEXunJKuh7XycKRADBvTr2VLgQ8ZngnvoOff3huHpoZBGnq7PQ6kVSx1H6rLTTQX7nrLMERLl/3Kv4b841tNOvrhxWyj1g7jo9e93aRX8YgoGdjts+jm61k06LPI4u/LRJt9j1177kQEXZPFfWCF9n26hN5LlmNUZ1xw5N8agx5EEJOicHOJWUAT3mZdQ1czuiivMU7PKdz5iW2KoJmjoR3EHaPJ4zM1pcZfHdPhj+u5J+l1WMCEU37jumNAdu9QSysXppC3ZOHHuOlGGgeC+FFChfuK4Bc4ha/FjwB8w0DQj4doTMuFZ3PVwDT2hEPQA4fQAE8lG0wNUFLUWHiTiCZr0Lg6eFcqgF1M+nNv5w2JE8TKMkXqi8c5VDoFuwOcvj54H1yDRjAh1aPUF8Ofg0iGlx0hKFzT9QJyiT9cJWfvOlG9C/+f/fNnuzOAn/pYncfB+RvkudFhSDzIBIb5ay3PeHPa8iC4xImg947sbK2N7U= Shariq.Mustquim@MBP-C02C32F6MD6R
            EOT
          + username   = "edcadmin"
        }

      + os_disk {
          + caching                   = "ReadOnly"
          + disk_size_gb              = 64
          + name                      = (known after apply)
          + storage_account_type      = "Standard_LRS"
          + write_accelerator_enabled = false
        }

      + source_image_reference {
          + offer     = "0001-com-ubuntu-server-focal"
          + publisher = "Canonical"
          + sku       = "20_04-lts"
          + version   = "latest"
        }
    }

  # module.nfs[0].azurerm_managed_disk.vm_data_disk[0] will be created
  + resource "azurerm_managed_disk" "vm_data_disk" {
      + create_option        = "Empty"
      + disk_iops_read_write = (known after apply)
      + disk_mbps_read_write = (known after apply)
      + disk_size_gb         = 128
      + id                   = (known after apply)
      + location             = "uaenorth"
      + name                 = "zandsas-nfs-disk01"
      + resource_group_name  = "shd-sas-k8s-rg-n"
      + source_uri           = (known after apply)
      + storage_account_type = "Standard_LRS"
      + tier                 = (known after apply)
      + zones                = []
    }

  # module.nfs[0].azurerm_managed_disk.vm_data_disk[1] will be created
  + resource "azurerm_managed_disk" "vm_data_disk" {
      + create_option        = "Empty"
      + disk_iops_read_write = (known after apply)
      + disk_mbps_read_write = (known after apply)
      + disk_size_gb         = 128
      + id                   = (known after apply)
      + location             = "uaenorth"
      + name                 = "zandsas-nfs-disk02"
      + resource_group_name  = "shd-sas-k8s-rg-n"
      + source_uri           = (known after apply)
      + storage_account_type = "Standard_LRS"
      + tier                 = (known after apply)
      + zones                = []
    }

  # module.nfs[0].azurerm_managed_disk.vm_data_disk[2] will be created
  + resource "azurerm_managed_disk" "vm_data_disk" {
      + create_option        = "Empty"
      + disk_iops_read_write = (known after apply)
      + disk_mbps_read_write = (known after apply)
      + disk_size_gb         = 128
      + id                   = (known after apply)
      + location             = "uaenorth"
      + name                 = "zandsas-nfs-disk03"
      + resource_group_name  = "shd-sas-k8s-rg-n"
      + source_uri           = (known after apply)
      + storage_account_type = "Standard_LRS"
      + tier                 = (known after apply)
      + zones                = []
    }

  # module.nfs[0].azurerm_managed_disk.vm_data_disk[3] will be created
  + resource "azurerm_managed_disk" "vm_data_disk" {
      + create_option        = "Empty"
      + disk_iops_read_write = (known after apply)
      + disk_mbps_read_write = (known after apply)
      + disk_size_gb         = 128
      + id                   = (known after apply)
      + location             = "uaenorth"
      + name                 = "zandsas-nfs-disk04"
      + resource_group_name  = "shd-sas-k8s-rg-n"
      + source_uri           = (known after apply)
      + storage_account_type = "Standard_LRS"
      + tier                 = (known after apply)
      + zones                = []
    }

  # module.nfs[0].azurerm_network_interface.vm_nic will be created
  + resource "azurerm_network_interface" "vm_nic" {
      + applied_dns_servers           = (known after apply)
      + dns_servers                   = (known after apply)
      + enable_accelerated_networking = false
      + enable_ip_forwarding          = false
      + id                            = (known after apply)
      + internal_dns_name_label       = (known after apply)
      + internal_domain_name_suffix   = (known after apply)
      + location                      = "uaenorth"
      + mac_address                   = (known after apply)
      + name                          = "zandsas-nfs-nic"
      + private_ip_address            = (known after apply)
      + private_ip_addresses          = (known after apply)
      + resource_group_name           = "shd-sas-k8s-rg-n"
      + virtual_machine_id            = (known after apply)

      + ip_configuration {
          + name                          = "zandsas-nfs-ip_config"
          + primary                       = (known after apply)
          + private_ip_address            = (known after apply)
          + private_ip_address_allocation = "dynamic"
          + private_ip_address_version    = "IPv4"
          + subnet_id                     = "/subscriptions/76f40aaa-eacd-4fd8-a046-3bd07855f6f8/resourceGroups/shd-network-rg-n/providers/Microsoft.Network/virtualNetworks/SHD-INF-VNET-n/subnets/shd-inf-sas-k8s-10.23.8.64-26-n"
        }
    }

  # module.nfs[0].azurerm_network_interface_security_group_association.vm_nic_sg will be created
  + resource "azurerm_network_interface_security_group_association" "vm_nic_sg" {
      + id                        = (known after apply)
      + network_interface_id      = (known after apply)
      + network_security_group_id = "/subscriptions/76f40aaa-eacd-4fd8-a046-3bd07855f6f8/resourceGroups/shd-network-rg-n/providers/Microsoft.Network/networkSecurityGroups/shd-inf-sas-k8s-10.23.8.64-26-n-nsg"
    }

  # module.nfs[0].azurerm_virtual_machine_data_disk_attachment.vm_data_disk_attach[0] will be created
  + resource "azurerm_virtual_machine_data_disk_attachment" "vm_data_disk_attach" {
      + caching                   = "ReadWrite"
      + create_option             = "Attach"
      + id                        = (known after apply)
      + lun                       = 10
      + managed_disk_id           = (known after apply)
      + virtual_machine_id        = (known after apply)
      + write_accelerator_enabled = false
    }

  # module.nfs[0].azurerm_virtual_machine_data_disk_attachment.vm_data_disk_attach[1] will be created
  + resource "azurerm_virtual_machine_data_disk_attachment" "vm_data_disk_attach" {
      + caching                   = "ReadWrite"
      + create_option             = "Attach"
      + id                        = (known after apply)
      + lun                       = 11
      + managed_disk_id           = (known after apply)
      + virtual_machine_id        = (known after apply)
      + write_accelerator_enabled = false
    }

  # module.nfs[0].azurerm_virtual_machine_data_disk_attachment.vm_data_disk_attach[2] will be created
  + resource "azurerm_virtual_machine_data_disk_attachment" "vm_data_disk_attach" {
      + caching                   = "ReadWrite"
      + create_option             = "Attach"
      + id                        = (known after apply)
      + lun                       = 12
      + managed_disk_id           = (known after apply)
      + virtual_machine_id        = (known after apply)
      + write_accelerator_enabled = false
    }

  # module.nfs[0].azurerm_virtual_machine_data_disk_attachment.vm_data_disk_attach[3] will be created
  + resource "azurerm_virtual_machine_data_disk_attachment" "vm_data_disk_attach" {
      + caching                   = "ReadWrite"
      + create_option             = "Attach"
      + id                        = (known after apply)
      + lun                       = 13
      + managed_disk_id           = (known after apply)
      + virtual_machine_id        = (known after apply)
      + write_accelerator_enabled = false
    }

  # module.node_pools["cas"].azurerm_kubernetes_cluster_node_pool.static_node_pool[0] will be created
  + resource "azurerm_kubernetes_cluster_node_pool" "static_node_pool" {
      + availability_zones           = []
      + enable_auto_scaling          = false
      + id                           = (known after apply)
      + kubernetes_cluster_id        = (known after apply)
      + max_pods                     = 110
      + mode                         = "User"
      + name                         = "cas"
      + node_count                   = 1
      + node_labels                  = {
          + "workload.sas.com/class" = "cas"
        }
      + node_taints                  = [
          + "workload.sas.com/class=cas:NoSchedule",
        ]
      + orchestrator_version         = "1.21.7"
      + os_disk_size_gb              = 200
      + os_disk_type                 = "Managed"
      + os_type                      = "Linux"
      + priority                     = "Regular"
      + proximity_placement_group_id = (known after apply)
      + spot_max_price               = -1
      + vm_size                      = "Standard_E16s_v3"
      + vnet_subnet_id               = "/subscriptions/76f40aaa-eacd-4fd8-a046-3bd07855f6f8/resourceGroups/shd-network-rg-n/providers/Microsoft.Network/virtualNetworks/SHD-INF-VNET-n/subnets/shd-inf-sas-k8s-10.23.8.64-26-n"
    }

  # module.node_pools["compute"].azurerm_kubernetes_cluster_node_pool.static_node_pool[0] will be created
  + resource "azurerm_kubernetes_cluster_node_pool" "static_node_pool" {
      + availability_zones           = []
      + enable_auto_scaling          = false
      + id                           = (known after apply)
      + kubernetes_cluster_id        = (known after apply)
      + max_pods                     = 110
      + mode                         = "User"
      + name                         = "compute"
      + node_count                   = 1
      + node_labels                  = {
          + "launcher.sas.com/prepullImage" = "sas-programming-environment"
          + "workload.sas.com/class"        = "compute"
        }
      + node_taints                  = [
          + "workload.sas.com/class=compute:NoSchedule",
        ]
      + orchestrator_version         = "1.21.7"
      + os_disk_size_gb              = 200
      + os_disk_type                 = "Managed"
      + os_type                      = "Linux"
      + priority                     = "Regular"
      + proximity_placement_group_id = (known after apply)
      + spot_max_price               = -1
      + vm_size                      = "Standard_E16s_v3"
      + vnet_subnet_id               = "/subscriptions/76f40aaa-eacd-4fd8-a046-3bd07855f6f8/resourceGroups/shd-network-rg-n/providers/Microsoft.Network/virtualNetworks/SHD-INF-VNET-n/subnets/shd-inf-sas-k8s-10.23.8.64-26-n"
    }

  # module.node_pools["stateful"].azurerm_kubernetes_cluster_node_pool.autoscale_node_pool[0] will be created
  + resource "azurerm_kubernetes_cluster_node_pool" "autoscale_node_pool" {
      + availability_zones           = []
      + enable_auto_scaling          = true
      + id                           = (known after apply)
      + kubernetes_cluster_id        = (known after apply)
      + max_count                    = 3
      + max_pods                     = 110
      + min_count                    = 1
      + mode                         = "User"
      + name                         = "stateful"
      + node_count                   = 1
      + node_labels                  = {
          + "workload.sas.com/class" = "stateful"
        }
      + node_taints                  = [
          + "workload.sas.com/class=stateful:NoSchedule",
        ]
      + orchestrator_version         = "1.21.7"
      + os_disk_size_gb              = 200
      + os_disk_type                 = "Managed"
      + os_type                      = "Linux"
      + priority                     = "Regular"
      + proximity_placement_group_id = (known after apply)
      + spot_max_price               = -1
      + vm_size                      = "Standard_D8s_v3"
      + vnet_subnet_id               = "/subscriptions/76f40aaa-eacd-4fd8-a046-3bd07855f6f8/resourceGroups/shd-network-rg-n/providers/Microsoft.Network/virtualNetworks/SHD-INF-VNET-n/subnets/shd-inf-sas-k8s-10.23.8.64-26-n"
    }

  # module.node_pools["stateless"].azurerm_kubernetes_cluster_node_pool.autoscale_node_pool[0] will be created
  + resource "azurerm_kubernetes_cluster_node_pool" "autoscale_node_pool" {
      + availability_zones           = []
      + enable_auto_scaling          = true
      + id                           = (known after apply)
      + kubernetes_cluster_id        = (known after apply)
      + max_count                    = 2
      + max_pods                     = 110
      + min_count                    = 1
      + mode                         = "User"
      + name                         = "stateless"
      + node_count                   = 1
      + node_labels                  = {
          + "workload.sas.com/class" = "stateless"
        }
      + node_taints                  = [
          + "workload.sas.com/class=stateless:NoSchedule",
        ]
      + orchestrator_version         = "1.21.7"
      + os_disk_size_gb              = 200
      + os_disk_type                 = "Managed"
      + os_type                      = "Linux"
      + priority                     = "Regular"
      + proximity_placement_group_id = (known after apply)
      + spot_max_price               = -1
      + vm_size                      = "Standard_D16s_v3"
      + vnet_subnet_id               = "/subscriptions/76f40aaa-eacd-4fd8-a046-3bd07855f6f8/resourceGroups/shd-network-rg-n/providers/Microsoft.Network/virtualNetworks/SHD-INF-VNET-n/subnets/shd-inf-sas-k8s-10.23.8.64-26-n"
    }

Plan: 26 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + aks_cluster_node_username = (known after apply)
  + aks_cluster_password      = (sensitive value)
  + aks_host                  = (known after apply)
  + cluster_api_mode          = "public"
  + cluster_name              = "zandsas-aks"
  + cluster_node_pool_mode    = "default"
  + jump_admin_username       = "edcadmin"
  + jump_private_ip           = (known after apply)
  + jump_public_ip            = (known after apply)
  + jump_rwx_filestore_path   = "/viya-share"
  + kube_config               = (sensitive value)
  + location                  = "uaenorth"
  + nat_ip                    = (known after apply)
  + nfs_admin_username        = "edcadmin"
  + nfs_private_ip            = (known after apply)
  + prefix                    = "zandsas"
  + provider                  = "azure"
  + provider_account          = "Shared (Dev/Test)"
  + rwx_filestore_endpoint    = (known after apply)
  + rwx_filestore_path        = "/export"

─────────────────────────────────────────────────────────────────────────────

Note: You didn't use the -out option to save this plan, so Terraform can't
guarantee to take exactly these actions if you run "terraform apply" now.
